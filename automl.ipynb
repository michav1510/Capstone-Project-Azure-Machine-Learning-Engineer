{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernel_info": {
      "name": "python3-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "colab": {
      "name": "automl.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cyS6gjVxETQ"
      },
      "source": [
        "# Automated ML\n",
        "\n",
        "TODO: Import Dependencies. In the cell below, import all the dependencies that you will need to complete the project.\n",
        "\n",
        "Below we are adding the dependencies.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4gCpykHtAWN"
      },
      "source": [
        "import logging\r\n",
        "import os\r\n",
        "import csv\r\n",
        "import joblib\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import pkg_resources\r\n",
        "import azureml.core\r\n",
        "\r\n",
        "\r\n",
        "from matplotlib import pyplot as plt\r\n",
        "from sklearn import datasets\r\n",
        "from azureml.core.experiment import Experiment\r\n",
        "from azureml.core.workspace import Workspace\r\n",
        "from azureml.train.automl import AutoMLConfig\r\n",
        "from azureml.core.dataset import Dataset\r\n",
        "from azureml.data.dataset_factory import TabularDatasetFactory\r\n",
        "from azureml.core.compute import AmlCompute\r\n",
        "from azureml.core.compute import ComputeTarget\r\n",
        "from azureml.core.compute_target import ComputeTargetException\r\n",
        "from azureml.pipeline.steps import AutoMLStep\r\n",
        "from azureml.widgets import RunDetails\r\n",
        "from azureml.core.environment import Environment \r\n",
        "from azureml.core.model import InferenceConfig \r\n",
        "from azureml.core.webservice import AciWebservice, Webservice\r\n",
        "from azureml.core.model import Model\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsY197u-tNjt"
      },
      "source": [
        "## Initialize Workspace\r\n",
        "Initialize a workspace object from persisted configuration. Make sure the config file is present at .\\config.json\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LL1sqpyQtYS5"
      },
      "source": [
        "ws = Workspace.from_config()\r\n",
        "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiIqby7xtcDW"
      },
      "source": [
        "## Create an Azure ML experiment\r\n",
        "Let's create an experiment named \"automlstep-classification\" and a folder to hold the training scripts. The script runs will be recorded under the experiment in Azure.\r\n",
        "\r\n",
        "The best practice is to use separate folders for scripts and its dependent files for each step and specify that folder as the `source_directory` for the step. This helps reduce the size of the snapshot created for the step (only the specific folder is snapshotted). Since changes in any files in the `source_directory` would trigger a re-upload of the snapshot, this helps keep the reuse of the step when there are no changes in the `source_directory` of the step.\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7Ay5ycrtcgO"
      },
      "source": [
        "experiment_name = 'Experiment_on_Heart-Failure-Prediction'\r\n",
        "project_folder = './capstone-classification-project'\r\n",
        "\r\n",
        "experiment = Experiment(ws, experiment_name)\r\n",
        "experiment"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-T2IP1NuEau"
      },
      "source": [
        "### Create or Attach an AmlCompute cluster\r\n",
        "We will need to create a [compute target](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#compute-target) for our AutoML run. In this tutorial, we get the default `AmlCompute` as our training compute resource.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaWa_B8nuEjN"
      },
      "source": [
        "amlcompute_cluster_name = \"aml-compute\"\r\n",
        "\r\n",
        "# Verify that cluster does not exist already\r\n",
        "try:\r\n",
        "    compute_target = ComputeTarget(workspace=ws, name=amlcompute_cluster_name)\r\n",
        "    print('Found existing cluster, use it.')\r\n",
        "except ComputeTargetException:\r\n",
        "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D2_V2',# for GPU, use \"STANDARD_NC6\"\r\n",
        "                                                           #vm_priority = 'lowpriority', # optional\r\n",
        "                                                           max_nodes=4)\r\n",
        "    compute_target = ComputeTarget.create(ws, amlcompute_cluster_name, compute_config)\r\n",
        "\r\n",
        "compute_target.wait_for_completion(show_output=True, min_node_count = 1, timeout_in_minutes = 10)\r\n",
        "# For a more detailed view of current AmlCompute status, use get_status()."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9QnLjTixETW"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "### Overview\n",
        "TODO: In this markdown cell, give an overview of the dataset you are using. Also mention the task you will be performing.\n",
        "\n",
        "\n",
        "TODO: Get data. In the cell below, write code to access the data you will be using in this project. Remember that the dataset needs to be external.\n",
        "\n",
        "The dataset I used is heart_failure_clinical_records_dataset.csv(https://www.kaggle.com/andrewmvd/heart-failure-clinical-data). It describes some recorded health indicators metrics. The data have almost 300 rows of these indicators recorded from patients.\n",
        "\n",
        "I am using this data in order to predict the DEATH_EVENT i.e. whether or not the patient deceased during the follow-up period (boolean). The features of the data are the following:\n",
        "\n",
        "age : The age of the patient.\n",
        "\n",
        "anaemia : Decrease of red blood cells or hemoglobin (boolean).\n",
        "\n",
        "creatinine_phosphokinase : Decrease of red blood cells or hemoglobin (boolean).\n",
        "\n",
        "diabetes : If the patient has diabetes (boolean).\n",
        "\n",
        "ejection_fraction : Percentage of blood leaving the heart at each contraction (percentage).\n",
        "\n",
        "high_blood_pressure : If the patient has hypertension (boolean).\n",
        "\n",
        "platelets : Platelets in the blood (kiloplatelets/mL).\n",
        "\n",
        "serum_creatinine : Level of serum creatinine in the blood (mg/dL).\n",
        "\n",
        "serum_sodium : Level of serum sodium in the blood (mEq/L).\n",
        "\n",
        "sex : Woman or man (binary).\n",
        "\n",
        "smoking : If the patient smokes or not (boolean).\n",
        "\n",
        "time : Follow-up period (days).\n",
        "\n",
        "DEATH_EVENT : If the patient deceased during the follow-up period (boolean).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLYXelcWxTVn"
      },
      "source": [
        "found = False\r\n",
        "key = \"Heart-Failure\"\r\n",
        "description_text = \"Heart Failure csv for prediction for the Capstone Project.\"\r\n",
        "\r\n",
        "if key in ws.datasets.keys(): \r\n",
        "        found = True\r\n",
        "        dataset = ws.datasets[key] \r\n",
        "        \r\n",
        "\r\n",
        "if not found:\r\n",
        "        # Create AML Dataset and register it into Workspace\r\n",
        "        example_data = 'https://github.com/michav1510/Capstone-Project-Azure-Machine-Learning-Engineer/blob/main/heart_failure_clinical_records_dataset.csv'\r\n",
        "        dataset = Dataset.Tabular.from_delimited_files(example_data)        \r\n",
        "        #Register Dataset in Workspace\r\n",
        "        dataset = dataset.register(workspace=ws,\r\n",
        "                                   name=key,\r\n",
        "                                   description=description_text)\r\n",
        "\r\n",
        "\r\n",
        "df = dataset.to_pandas_dataframe()\r\n",
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "gather": {
          "logged": 1598423890461
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "L1sAcuYfxETW"
      },
      "source": [
        "ws = Workspace.from_config()\n",
        "\n",
        "# choose a name for experiment\n",
        "experiment_name = 'your experiment name here'\n",
        "\n",
        "experiment=Experiment(ws, experiment_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPvodPCSxETX"
      },
      "source": [
        "## AutoML Configuration\n",
        "\n",
        "TODO: Explain why you chose the automl settings and cofiguration you used below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gather": {
          "logged": 1598429217746
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "-mgIP10FxETX"
      },
      "source": [
        "automl_settings = {\n",
        "    \"experiment_timeout_minutes\": 30,\n",
        "    \"n_cross_validations\": 2,\n",
        "    \"enable_early_stopping\": True, \n",
        "    \"max_concurrent_iterations\": 5,\n",
        "    \"primary_metric\" : 'accuracy'\n",
        "}\n",
        "\n",
        "automl_config = AutoMLConfig(compute_target=compute_target,\n",
        "                             task = \"classification\",\n",
        "                             training_data=dataset,\n",
        "                             label_column_name=\"DEATH_EVENT\",   \n",
        "                             path = project_folder,\n",
        "                             featurization= 'auto',\n",
        "                             debug_log = \"automl_errors.log\",\n",
        "                             **automl_settings\n",
        "                            )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "gather": {
          "logged": 1598431107951
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "dwODMBtUxETX"
      },
      "source": [
        "# TODO: Submit your experiment\n",
        "remote_run = experiment.submit(automl_config, show_output= True)\n",
        "remote_run.wait_for_completion()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UPxVt3GxETX"
      },
      "source": [
        "## Run Details\n",
        "\n",
        "OPTIONAL: Write about the different models trained and their performance. Why do you think some models did better than others?\n",
        "\n",
        "In the cell below, we use the `RunDetails` widget to show the different experiments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gather": {
          "logged": 1598431121770
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "a4Dhw2wmxETY"
      },
      "source": [
        "RunDetails(remote_run).show()\r\n",
        "for children_run in remote_run.get_children():\r\n",
        "    print('------')\r\n",
        "    print(children_run)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzHR_zZGxETY"
      },
      "source": [
        "## Best Model\n",
        "\n",
        "TODO: In the cell below, get the best model from the automl experiments and display all the properties of the model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gather": {
          "logged": 1598431425670
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "ThChoYTaxETY"
      },
      "source": [
        "best_run, fitted_model = remote_run.get_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DG56YXRX3eNU"
      },
      "source": [
        "Below we have the best run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vwy4ho6C3hAi"
      },
      "source": [
        "best_run"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WaIZktW2_HM"
      },
      "source": [
        "Below we will see the best run metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7P6JutP22qG7"
      },
      "source": [
        "best_run.get_metrics()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIA8TQmg3B3Q"
      },
      "source": [
        "Below we will see the best run details"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJn-3gC82srk"
      },
      "source": [
        "best_run.get_details()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rl4NORXs3HE0"
      },
      "source": [
        "Below we will see the properties of best run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55ddmUr32yZO"
      },
      "source": [
        "best_run.get_properties()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqivP7HZ35vw"
      },
      "source": [
        "Below we save the best model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gather": {
          "logged": 1598431426111
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "mNqA3qiqxETY"
      },
      "source": [
        "best_run.register_model(model_name='best_run_capston_automl', model_path='./outputs/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0ANjgmbxETY"
      },
      "source": [
        "## Model Deployment\n",
        "\n",
        "Remember you have to deploy only one of the two models you trained.. Perform the steps in the rest of this notebook only if you wish to deploy this model.\n",
        "\n",
        "TODO: In the cell below, register the model, create an inference config and deploy the model as a web service."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gather": {
          "logged": 1598431435189
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "uV3bqbB-xETZ"
      },
      "source": [
        "model = remote_run.register_model(model_name = 'best_run_automl.pkl')\r\n",
        "\r\n",
        "environment = best_run.get_environment()\r\n",
        "entry_script='inference/scoring.py'\r\n",
        "best_run.download_file('outputs/scoring_file_v_1_0_0.py', entry_script)\r\n",
        "\r\n",
        "\r\n",
        "inference_config = InferenceConfig(entry_script = entry_script, environment = environment)\r\n",
        "\r\n",
        "deployment_config = AciWebservice.deploy_configuration(cpu_cores = 1, \r\n",
        "                                                    memory_gb = 1, \r\n",
        "                                                    auth_enabled= True, \r\n",
        "                                                    enable_app_insights= True)\r\n",
        "\r\n",
        "service = Model.deploy(ws, \"aciservice\", [model], inference_config, deployment_config)\r\n",
        "service.wait_for_deployment(show_output = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1598431657736
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "eprQFJpwxETZ"
      },
      "source": [
        "TODO: In the cell below, send a request to the web service you deployed to test it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gather": {
          "logged": 1598432707604
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "ynZDY_6LxETZ"
      },
      "source": [
        "%run endpoint.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1598432765711
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "kiC71PF2xETZ"
      },
      "source": [
        "TODO: In the cell below, print the logs of the web service and delete the service"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "GDCTlEFGxETZ"
      },
      "source": [
        "print(service.get_logs())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnOWpnzao6O6"
      },
      "source": [
        "service.delete()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}